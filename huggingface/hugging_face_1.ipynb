{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to find latest models by most downlaoded. Find model and saving that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelInfo(id='1231czx/llama3_it_ultra_list_and_bold500', author=None, sha=None, created_at=datetime.datetime(2024, 9, 3, 12, 55, 17, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=25854145, downloads_all_time=None, gated=None, gguf=None, inference=None, likes=2, library_name='transformers', tags=['transformers', 'safetensors', 'llama', 'text-classification', 'arxiv:1910.09700', 'autotrain_compatible', 'text-generation-inference', 'endpoints_compatible', 'region:us'], pipeline_tag='text-classification', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=None, siblings=None, spaces=None, safetensors=None)]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary class from Hugging Face Hub\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Create an instance of the API\n",
    "api = HfApi()\n",
    "\n",
    "# Return the filtered list from the Hub using direct parameters\n",
    "models = api.list_models(\n",
    "    task=\"text-classification\",  # Directly specify the task\n",
    "    sort=\"downloads\",            # Sort by the number of downloads\n",
    "    direction=-1,                # Sort in descending order\n",
    "    limit=1                      # Limit the result to the top model\n",
    ")\n",
    "\n",
    "# Store as a list\n",
    "model_list = list(models)\n",
    "\n",
    "# Print the result to see the top model\n",
    "print(model_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# Define the model ID\n",
    "modelId = \"1231czx/llama3_it_ultra_list_and_bold500\"\n",
    "\n",
    "# Load the model from the Hugging Face Hub\n",
    "model = AutoModel.from_pretrained(modelId)\n",
    "\n",
    "# Define the save directory\n",
    "save_directory = f\"models/{modelId.replace('/', '_')}\"\n",
    "\n",
    "# Save the model to the specified directory\n",
    "model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face built the dataset package for interacting with datasets. There are a lot of convenient functions, including load_dataset_builder which we just used. After inspecting a dataset to ensure its the right one for your project, it's time to load the dataset! For this, we can leverage input parameters for load_dataset to specify which parts of a dataset to load, i.e. the \"train\" dataset for English wikipedia articles.\n",
    "\n",
    "The load_dataset module from the datasets package is already loaded for you. Note: the load_dataset function was modified for the purpose of this exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': Value(dtype='string', id=None), 'qid': Value(dtype='string', id=None), 'name': Value(dtype='string', id=None), 'input': Value(dtype='string', id=None), 'instruction': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataset is 1560888\n"
     ]
    }
   ],
   "source": [
    "# Load the module\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "\n",
    "# Create the dataset builder\n",
    "reviews_builder = load_dataset_builder(\"derenrich/wikidata-en-descriptions-small\")\n",
    "\n",
    "# Print the features\n",
    "print(reviews_builder.info.features) ## these are columns\n",
    "\n",
    "\n",
    "# Load the train portion of the dataset\n",
    "wikipedia = load_dataset(\"derenrich/wikidata-en-descriptions-small\", split=\"train\")\n",
    "\n",
    "print(f\"The length of the dataset is {len(wikipedia)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Produce a short Wikidata description for this Wikipedia article ### Input: The 1964–65 DDR-Oberliga was the 16th season of the DDR-Oberliga, the first tier of league football in East Germany. The league was contested by fourteen teams. National People's Army club ASK Vorwärts Berlin won the championship, the club's fourth of six national East German championships all up. Bernd Bauchspieß of BSG Chemie Leipzig was the league's top scorer with 14 goals, becoming the first player to finish as top scorer on three occasions. For the third time the title East German Footballer of the year was awarded, going to Horst Weigang of SC Leipzig. On the strength of the 1964–65 title Vorwärts qualified for the 1965–66 European Cup where the club was knocked out by Manchester United in the first round. Seventh-placed club SC Aufbau Magdeburg qualified for the 1965–66 European Cup Winners' Cup as the seasons FDGB-Pokal winner and was knocked out by West Ham United in the quarter-finals. Fourth-placed SC Leipzig qualified for the 1965–66 Inter-Cities Fairs Cup where it was knocked out in the second round by Leeds United. ### Response: sports season\n"
     ]
    }
   ],
   "source": [
    "# Filter the documents\n",
    "filtered = wikipedia.filter(lambda row: \"football\" in row[\"text\"])\n",
    "\n",
    "# Create a sample dataset\n",
    "example = filtered.select(range(1))\n",
    "\n",
    "print(example[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QID: Q563628, Name: 1964–65 DDR-Oberliga, Text: Instruction: Produce a short Wikidata description for this Wikipedia article ### Input: The 1964–65 DDR-Oberliga was the 16th season of the DDR-Oberliga, the first tier of league football in East Germany. The league was contested by fourteen teams. National People's Army club ASK Vorwärts Berlin won the championship, the club's fourth of six national East German championships all up. Bernd Bauchspieß of BSG Chemie Leipzig was the league's top scorer with 14 goals, becoming the first player to finish as top scorer on three occasions. For the third time the title East German Footballer of the year was awarded, going to Horst Weigang of SC Leipzig. On the strength of the 1964–65 title Vorwärts qualified for the 1965–66 European Cup where the club was knocked out by Manchester United in the first round. Seventh-placed club SC Aufbau Magdeburg qualified for the 1965–66 European Cup Winners' Cup as the seasons FDGB-Pokal winner and was knocked out by West Ham United in the quarter-finals. Fourth-placed SC Leipzig qualified for the 1965–66 Inter-Cities Fairs Cup where it was knocked out in the second round by Leeds United. ### Response: sports season\n"
     ]
    }
   ],
   "source": [
    "# Print specific columns for all rows\n",
    "for row in filtered:\n",
    "    print(f\"QID: {row['qid']}, Name: {row['name']}, Text: {row['text']}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Sentiment Analysis Output: [{'label': 'POSITIVE', 'score': 0.9992846846580505}]\n",
      "Model-Specific Sentiment Analysis Output: [{'label': 'POSITIVE', 'score': 0.9992846846580505}]\n"
     ]
    }
   ],
   "source": [
    "# Import the pipeline function from the transformers library\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create a sentiment-analysis pipeline using the default model\n",
    "task_pipeline = pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "# Create a sentiment-analysis pipeline using a specific pre-trained model\n",
    "model_pipeline = pipeline(model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"I love using the Hugging Face library!\"\n",
    "\n",
    "# Predict the sentiment using the default sentiment-analysis pipeline\n",
    "task_output = task_pipeline(input_text)\n",
    "\n",
    "# Predict the sentiment using the specific model pipeline\n",
    "model_output = model_pipeline(input_text)\n",
    "\n",
    "# Print the outputs\n",
    "print(f\"Default Sentiment Analysis Output: {task_output}\")\n",
    "print(f\"Model-Specific Sentiment Analysis Output: {model_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1c4b87ce8d41588a8b9d519ea4cb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b318ad9731140dfbb23947ec33fd8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f63930a29949f382d00b1c83af94e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb99f297c7e410abc7228f4f59b13a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'ORG', 'score': np.float32(0.994665), 'word': 'Hugging Face Inc', 'start': 0, 'end': 16}, {'entity_group': 'LOC', 'score': np.float32(0.9983915), 'word': 'New York', 'start': 40, 'end': 48}]\n"
     ]
    }
   ],
   "source": [
    "# Create a named entity recognition pipeline\n",
    "ner_pipeline = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Analyze named entities in a sentence\n",
    "result = ner_pipeline(\"Hugging Face Inc. is a company based in New York.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment using AutoClasses: POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries from transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# Download the model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Create the sentiment-analysis pipeline using the specified model and tokenizer\n",
    "sentiment_analysis = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"I love using the Hugging Face library!\"\n",
    "\n",
    "# Predict the sentiment\n",
    "output = sentiment_analysis(input_text)\n",
    "\n",
    "# Print the sentiment label\n",
    "print(f\"Sentiment using AutoClasses: {output[0]['label']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are you???\n"
     ]
    }
   ],
   "source": [
    "# Import the AutoTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Download the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Normalize the input string\n",
    "output = tokenizer.backend_tokenizer.normalizer.normalize_str(\"How are you???\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38e04d97b1644b19b3e9d32fc4cd824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac42ebeeccd408bb8aa96af3b0c2770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfa8e5919414d8f8aa2488eb14adcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618d34554ba546c997d4f2dade084b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3ca8451afb4b61acb416b61b3ea55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT tokenizer: ['P', 'ine', 'apple', 'Ġon', 'Ġpizza', 'Ġis', 'Ġpretty', 'Ġgood', ',', 'ĠI', 'Ġguess', '.']\n",
      "DistilBERT tokenizer: ['pine', '##apple', 'on', 'pizza', 'is', 'pretty', 'good', ',', 'i', 'guess', '.']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary classes from the transformers library\n",
    "from transformers import GPT2Tokenizer, DistilBertTokenizer\n",
    "\n",
    "# Download the GPT tokenizer\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Define your input text\n",
    "input_text = \"Pineapple on pizza is pretty good, I guess.\"\n",
    "\n",
    "# Tokenize the input using GPT-2 tokenizer\n",
    "gpt_tokens = gpt_tokenizer.tokenize(text=input_text)\n",
    "\n",
    "# Repeat for DistilBERT\n",
    "distil_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "distil_tokens = distil_tokenizer.tokenize(text=input_text)\n",
    "\n",
    "# Compare the output\n",
    "print(f\"GPT tokenizer: {gpt_tokens}\")\n",
    "print(f\"DistilBERT tokenizer: {distil_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
